%% template.tex
%% from
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE!
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/

\documentclass[10 pt,conference,final,]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at:
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex

\usepackage{graphicx}

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\interdisplaylinepenalty=2500
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%

%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )



%% BEGIN MY ADDITIONS %%


\usepackage{nohyperref}

% Pandoc toggle for numbering sections (defaults to be off)
\setcounter{secnumdepth}{0}


% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


% Pandoc citation processing
%From Pandoc 3.1.8
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

%% END MY ADDITIONS %%


\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Intelligent Automation of SFO Crime Prediction using Multiple
Artifical Intelligence Methods}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations

\author{

%% ---- classic IEEETrans wide authors' list ----------------
\IEEEauthorblockN{
Praveen Kuruvangi Parameshwara\IEEEauthorrefmark{1},Shilpa
Gupta\IEEEauthorrefmark{2}%%
}


%% ----------------------------------------------------------

%% ---- classic IEEETrans one column per institution --------
 %%
%% ----------------------------------------------------------





%% ---- one column per author, classic/default IEEETrans ----

%% ----------------------------------------------------------

}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
%
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3},
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
Crime needs a broad understanding of its patterns and reasons behind
specific types that happen in certain areas only. The crime pattern
theory provides the explanation of distribution of criminal events and
its variations. Crime generators and crime attractor concentrate in the
places that include frequent routine movements of the population to
create hot and cold spots of crime. The offender is more often
comfortable with frequently committed crimes and prefers to commit these
in the places that they are most familiar with. These offenders can be
distinguished based on the type of crimes that fall into specific
incident categories. Identifying these categories help to categorize not
only frequently occurring crime locations but also facilitate the police
department to consider the type of support or action that needs to be
planned. Special analysis of crimes and its categories are essential to
understand the frequency, time and its patterns. This paper showcases
the use of different Artificial Intelligence techniques and compares
their behavior and outcomes which includes different machine learning
and deep learning techniques like random forest, K-nearest neighbor,
Artificial Neural Network, TabNet and Time Series. These are different
flavors of Artificial intelligence and also interactive dashboards and
web applications are supported to visualize the hidden patterns and in
depth details the different features. The flexibility of the paper is
extended to support any type of crime dataset with a minor initial data
streamline process and complete end to end flow is built using only a
python program to reduce the infrastructure cost. The benefit from this
paper is for the police stations to plan for more staffing to avoid the
occurance of crimes and push towards prevention steps. It helps the
policy maker to visualize and provide more knowledge on the crime
occurance and prediction.
\end{abstract}

% keywords
\begin{IEEEkeywords}
Artificial Intelligence; Machine Learning; Deep Learning; TabNet; Crime
Pattern Theory
\end{IEEEkeywords}

% use for special paper notices



% make the title area
\maketitle

% no keywords

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle


\section{I. Introduction}\label{i.-introduction}

Crime is characterized as an ``act of felony or grave offense against
society or someone else's property which is prohibited by law. As noted
in {[}1{]} crime does not happen evenly across all places and that
specific types of crime tend to occur more often in certain areas that
are called crime hotspots {[}2{]}. Hence, the spatial analysis {[}3{]}
of different types of crimes along with the areas of occurrence helps in
accurately predicting the different types of crime expected to occur in
future. {[}4{]} has shown to improve prediction of the time and the day
of crime. Accurate forecasting of crime hotspots helps in effective
management of law enforcement, see {[}5{]} and {[}6{]} in mitigating the
crime, hence improving the safety of the communities. {[}7{]} is an
excelent introduction to unintended harm that can be introduced in
machine learning life cycle. We should be more thoughtful about machine
learning application to apply on social problems because decisions made
as a result of the Machine learning can impact on people's life. In this
paper we analyze the crime data with the intention to support police
superintendent or staff in making staffing decisions.

With this objective, in the paper we illustrate the systematic process
of understanding different factors that are helpful in predicting crimes
based on historical data. We also explore the background work associated
with crime analysis and summarise the research done in the field of
crime analysis using ML and different approaches.

\section{II. Background}\label{ii.-background}

Crimes happens at certain areas, and it is illegal activities against
society or someone else's property. Crimes are increasing continuously
due to the awareness in criminals of the technological enhancements,
modern devices, and even social media. The crime offender rather than
venturing unknown territories, frequently commit crimes in comfort zones
or places where they are familiar such as home, work, school, shopping,
and entertainment areas. Crime analysis deals with crime classification,
investigating and detecting along with their connections to understand
its occurrence and patterns. There are quite a few papers that are
published to analyze crime and have used machine learning approaches to
predict the crime categories. The analysis were carried out on different
dataset using different approaches but same method for different
datasets were not considered. There are different tools and languages
are used to support, visualize and build different algorithms.

\section{III. Related Works}\label{iii.-related-works}

Many of the papers are focusing only on machine learning approach
because of dataset is falling into categorization methods and explored
the different patterns, attributes and categories of crimes that are
associated with data. {[}8{]} gives an overview of the machine learning
classification algorithms for the crime classification, but deals with
only a few categories of crime and limited parameters associated with
the ML approach. {[}9{]} reviews how artificial intelligence approaches
have been utilized in the crime prediction field. This gives us insight
on data collection, pre-processing, classification, pattern
identification and finally, the comparison of different data mining. The
authors also explored artificial neural network methods on the crime
data based on weekdays and weekends using 100 hidden layers and adam
solver but the accuracy had dropped very low. The paper {[}10{]}
combines social media and offline sources to isolate crime behavior. The
model categorizes an individual as a suspect, normal, or a criminal but
it is completely at the higher level and further investigation and other
processes needs to be carried out to reduce false positives and false
negatives. This is limited to specific types of data and text. The paper
{[}11{]} gives a good overview of association mining, clustering,
classification technique, correlation, and regression but not
breakthrough in any of the methods. {[}12{]} proposes approaches to
identify patterns from crime records to aid in investigation, control
and prevention.

The paper {[}13{]} explored quite a few things towards predicting crimes
that happen at different places and categories of crime that have
occurred at a specific place with accuracy depending on number of
classes. The paper utilized different ML techniques to analyze and
predict the crimes. It gives us a path on how to deal with huge amounts
of data for analysis and model creation. Random Forest, Adaboost and
Gradient boosting gave good accuracy for different classes. They also
talk about KNN and Decision tree with depth of 5 for better accuracy.
The paper talked about ANN Initially but there is not much importance or
usage of ANN. It provides details of accuracy of different models for
reduction in classes but no details about any class. Even though the
accuracy of naive Bayes and KNN is lower compared to random forest,
Adaboost and gradient boosting but they are considered prediction
without more providing details behind the same. The model and other
factors are specific to the San Francisco dataset. Analysis on different
cities will give more clarity on the performance of the models.
Effective visualization can still be done in different ways, but it is
not defined, and no analysis done on resolution.

Even Though many papers explored the usage of Machine learning and
Artificial neural network methods, the efficient and robustness of these
methods are not much utilized. And also, the advanced methods like
TabNet, successful achievement of the higher accuracy and flexibility of
end-to-end usage of only python libraries are not considered.

In this paper, the San Francisco dataset is considered as an important
dataset because of geographical location. It is one of the busiest
cities in the United States of America and it facilitates air, water and
land transportation and also contains people from different diversity at
different social standards. It is covered with more bay areas and
supports more sea transportation. As it has a thick population, high
transportation, diversities and more tourist attractions, it is prone to
have more crimes. The approach is also extended to Boston crime dataset
for better usage of defined methods. In order to discover the hidden
secret of the crimes data we apply not only machine learning approaches
but also different flavors of Artificial Intelligence such as Artificial
neural network, Tabnet which is a customized method and other effective
methods for detecting crimes in the San Francisco and Boston regions.
These models and methods not only perform better but also facilitate
better hyperparameter tuning techniques.

\section{IV. Methodology}\label{iv.-methodology}

The goal of the project is to analyze and visualize the spatial and
temporal relationship of crimes on various attributes and predict the
category of crime in a particular location, address the limitation of
existing papers and further look towards the enhancement to explore the
usage of ANN and different AI methodology. Paper shows more focus
towards the infrastructure cost to facilitate the use of only python
language and its libraries to build all the requirements of the project
including interactive dashboard and web application. The flexibility of
the project is to use the complete approach on different cities' crime
dataset like BOSTON to showcase its analysis, performance and effective
metrics to provide more meaning to the model and its architecture.
Explore the possibility to relate the data skewness to the population or
poverty, or others based on the area using census data.

\subsection{A. Data Acquisition}\label{a.-data-acquisition}

The data for the analysis was downloaded from San Francisco Police
Department Crime incident reporting system (https://data.sfgov.org ).
The data contains the details of the crime from 2003 to 2022. The data
consists of two csv files, the first csv file has data from 2003 to 2018
and the second is from 2018 to 2022. The data 2003 to 2018 contains 37
incident categories whereas 2018 to 2022 contains 50 incident
categories. Boston crime data obtained from boston website
(https://data.boston.gov/dataset) contains historical data of the year
2022 from the police department incident report. The data consists of
120 incident categories.

\subsection{B. Data Preprocessing}\label{b.-data-preprocessing}

The quality of data helps in providing valuable information and helps in
building the models. Some of the methods that are followed to improve
the quality of the data are data cleaning which involve removing the
invalid or unnecessary rows, addressing the missing values, data
transformation which involves extraction of new features from existing
attributes and combining the required attributes to create the new
features, data reduction involves discarding the null record or
attributes that are not required or correlated and data conversion
involves the conversion of character categorical to numeric categorical.
The streamlining of the data with defined attributes are taken care to
facilitate the use of most of the crime dataset to use this analysis and
its different approches.

\subsection{C. Visualization and
Presentation}\label{c.-visualization-and-presentation}

The data obtained is processed to handle missing values then data
formatting before performing exploratory data analysis. The attributes
time of day, hour, latitude, longitude, and police distinct are highly
correlated attributes and important factors for the crimes. Fig. 1 shows
the incident count on different days. It is observed that most of the
crimes happen on Friday and most frequently occurring crimes are theft,
burglary, robbery, missing person, and drugs. It is observed that there
are quick resolutions for cases like robbery, burglary, and assault.
Fig. 2 shows the geographical view of the crimes in the San Francisco
region. More crimes are committed in the north-east part of San
Francisco. Fig. 3 and Fig. 4 represent the high density of the Top crime
categories in the San Francisco region.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{img/fig1} 

}

\caption{Crime analysis based on Day of week, Police District and its resolution}\label{fig:unnamed-chunk-1}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig2} 

}

\caption{High number of incidents concentrated in the mission district of San Francisco}\label{fig:unnamed-chunk-2}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig3} 

}

\caption{High density of different incident categories}\label{fig:unnamed-chunk-3}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{img/fig4} 

}

\caption{Top incident categories}\label{fig:unnamed-chunk-4}
\end{figure}

Fig. 5 shows the heat map of incidents based on the weekdays and
brighter represents the hotspots of the categories. Fig 6 shows the
heatmap of incidents based on the time of the day. Most of the crimes
are happening in the afternoon and evening hours. Fig 7 represents the
heat map representation based on the season. It shows spring and autumn
are favorable for crime cases.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig5} 

}

\caption{Incidents heat map based on the day of the week}\label{fig:unnamed-chunk-5}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig6} 

}

\caption{Incidents heat map based on the time of day}\label{fig:unnamed-chunk-6}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig7} 

}

\caption{Incidents heat map based on the time of day}\label{fig:unnamed-chunk-7}
\end{figure}

Fig. 8 shows the attribute analysis based on the correlation between
them. The scale from 0 to 1 indicates the correlation and higher the
value closer to the relation of the attributes. Fig. 9 shows the number
of crimes on specific days of the week. It shows crime occurrences every
Sunday. The count has reached 300 on specific Sunday in a year and the
minimum crime count on Sunday is 200.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig8} 

}

\caption{Correlation analysis of different Attributes}\label{fig:unnamed-chunk-8}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{img/fig9} 

}

\caption{Number of crimes occurred on every Sunday}\label{fig:unnamed-chunk-9}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/fig10} 

}

\caption{Top crimes occurred based on the map}\label{fig:unnamed-chunk-10}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/fig11} 

}

\caption{Crime count based on the year}\label{fig:unnamed-chunk-11}
\end{figure}

Fig. 10 shows the scatter plot of Top crimes across the San Francisco
region. The analysis in Fig. 11 shows that the number of crimes had
decreased during 2020, it might be because of Pandemic. The crimes are
occurring mostly during afternoon hours, and few are happening during
evening hours. If we analyze the yearly trends, the occurrence of the
crimes has changed from fall to winter after the pandemic. Analysis of
historical data from 2003 to 2018 gives more meaningful insights on the
data pattern, its trend and important points to choose the models.

The data of San Francisco from the year 2018 onwards shows quite
deviation as follows.

\begin{itemize}
\tightlist
\item
  The number of crime categories have increased.
\item
  Theft is the highest number of crimes that has been occurring
  continuously.
\item
  Missing people crimes have dominated in recent years.
\item
  It looks like the middle of the week which is Wednesday is tagged to
  Drug offense.
\item
  Crime count has increased in proportion to population growth.
\item
  Crimes more often occurring in the afternoon and pushing towards
  evening hours.
\item
  More crimes that were occuring during winter in early 2018 has shifted
  to other seasons making winter quite non-crime seasons in the recent
  years.
\end{itemize}

This shows that it is always better to revisit and train the models to
the recent data to be more effective.These analysis drives the use of
different models like Random Forest, K-nearest neighbor, ANN, Tablet and
time series to understand the behavior and patterns of the data.

\section{V. Classification Models}\label{v.-classification-models}

Evaluation of different models are driven through the confusion metrics
that contain the values of True positive, False Positive, True Negative
and False Negative. These values helps in deriving False Positive rate
and False Negative rate to measure disproportionate model performance
errors. The fraction of negative (not falling to the same category) and
positive (same category) that are incorrectly predicted are also
reported. These metrics provide values for different errors and provide
better understanding of classification.

\subsection{A. Setup}\label{a.-setup}

Python libraries such as seaborn, matplotlib and geopandas are used for
visualization. The libraries such as pytorch, sklearn and tensorflow are
widly used as part of the models. In design of webapps and interactive
dashboard folium, ipywidgets and mercury are much useful.

\subsection{B. Models}\label{b.-models}

The experiment is carried out by considering different Artificial
Intelligence methods to fulfill the crime categorization techniques. The
accuracy of the models is between 83 -- 98 \% achieved through different
ML and AI approaches. All metrics reported at the .2 decision threshold.

\subsubsection{(1). Random Forest}\label{random-forest}

Random Forest is an ensemble supervised machine learning algorithm for
classification and regression problems. It involves building multiple
decision trees on different samples and aggregating the predictions
using a majority vote for classification. Fig. 12 shows the confusion
matrix for Random Forest.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig12} 

}

\caption{Confusion metrics for Random Forest}\label{fig:unnamed-chunk-12}
\end{figure}

\subsubsection{(2). K-nearest neighbors
(KNN)}\label{k-nearest-neighbors-knn}

The k-nearest neighbors (KNN) algorithm is a type of supervised machine
learning algorithm used to solve classification. The algorithm estimates
the likelihood that a data point will become a member of one group or
another based on what group the data points nearest to it belong to. It
is a non-parametric algorithm because it is robust to underlying
distributions of the data. Fig. 13 shows the confusion matrix for
k-nearest neighbors.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/fig13} 

}

\caption{Confusion metrics for K-Nearest Neighbor}\label{fig:unnamed-chunk-13}
\end{figure}

\subsubsection{(3). Artificial neural
networks}\label{artificial-neural-networks}

Artificial neural networks are human brain cells inspired systems which
are intended to replicate the way that humans learn. Neural networks
consist of input and output layers, as well as (in most cases) hidden
layers consisting of units that transform the input into something to
use by output layer. These layers are interconnected and consist of
neurons. The first layer sends data to the second layer, which in turn
sends the next output to the third layer. ANNs are considered in
non-linear statistical data modeling tools where the complex
relationships between inputs and outputs are modeled. Fig. 14 shows the
confusion matrix for Artificial neural networks.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/ANN} 

}

\caption{Confusion metrics for Artificial Neural Network}\label{fig:unnamed-chunk-14}
\end{figure}

\subsubsection{(4). TabNet}\label{tabnet}

TabNet, {[}14{]}, is a deep tabular data learning architecture and one
of the first transformer based models that uses sequential attention to
choose particular features to reason from at each decision step. The
TabNet encoder is composed of a feature transformer, an attentive
transformer and feature masking. A split block divides the processed
representation to be used by the attentive transformer of the subsequent
step as well as for the overall output. For each step, the feature
selection mask provides interpretable information about the model's
functionality, and the masks can be aggregated to obtain global feature
important attribution. The TabNet decoder is composed of a feature
transformer block at each step.

In the feature transformer block, a 4-layer network is used, where 2 are
shared across all decision steps and 2 are decision step-dependent. Each
layer is composed of a fully-connected (FC) layer, BN and GLU
nonlinearity. An attentive transformer block is a single layer mapping
modulated with a prior scale information which aggregates how much each
feature has been used before the current decision step. sparsemax is
used for normalization of the coefficients, resulting in sparse
selection of the salient features. There are different parameters for
fine tuning the model for better performance. The parameters like
learning rate, epochs, decay rate, patience and batch size gives better
control of the models.

Some of the initial methods followed in the paper such as lerning rate
to be 0.020, epochs set to 20 and a decay rate of 0.95 is applied then
fit the model to our data. The train and validation sets are evaluated
for a total of 30 iterations (epochs). The patience parameter shows the
improvement in metrics ans help to get the best weights. The batch size
of 10000 was selected based on recommendations from TabNet's paper (
batch size is up to 10\% of the total data).

\subsubsection{(5). Time Series Analysis}\label{time-series-analysis}

Crime patterns also have a strong time based component and hence it
falls into time-series forecasting methods. Time-series forecasting is a
method that consider the historical and current data to predict future
values over a period of time. The past data is analyzed to make informed
decisions this guides our business strategy and help us understand
future trends. Using time series models it is good to forecast the
number of crimes that occur in the future. This can be drilled down
further up to different category predictions. Fig. 15 shows the
confusion matrix for Tabnet.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{img/TabNet} 

}

\caption{Confusion metrics for TabNet}\label{fig:unnamed-chunk-15}
\end{figure}

Table I represents the Root Mean Square Error percentage for the time
series model. Lower the error percentage better the performance of the
model.

\begin{table}
\centering
\caption{\label{tab:unnamed-chunk-16}RMSE of the time series model}
\centering
\begin{tabular}[t]{l|l|l|l}
\hline
Model & SFO(2003-18) & SFO(2018-22) & Boston(2022)\\
\hline
TimeSeries & 37.33 \% & 42.56 \% & 26.89 \%\\
\hline
\end{tabular}
\end{table}

\section{VI. Results and Discussion}\label{vi.-results-and-discussion}

We always approach ML algorithms for classification problems, but Deep
learning models and TabNet are also good for classification problems on
tabular data. To build the model, model's hyperparameter and different
features are important factors. In the case of RandomForest using
entropy criterion gives better accuracy than Gini Criterion. The number
of estimators in K-Nearest Neighbor plays a significant role in the
algorithm. In Artificial Neural Network, deep neural network
architecture, activation, optimizer, and loss should be carefully chosen
to get better performance. Learning, decay rate and batch size plays a
major role in TabNet. Time series depends on how data is closely related
to the previous trends. It is a good practice to keep a smaller number
of classes or group them to similar classes to get better accuracy. High
amount of quality data enforces the best fine tuning of the model.
Uniqueness and data consistency are important factors to build the
model. Building different diversified models provide an opportunity to
weigh them to consider the best models for prediction.

\section{VII. Evaluation and
Reflection}\label{vii.-evaluation-and-reflection}

Metrics like accuracy provides the confidence to identify the better
performance of the model. Confusion matrix helps in visual
representation of the prediction and its deviation. Classification
reports provide the different metrics like precision, recall, f1-score
for different classes of the categories. These gives better pictures on
how the model is good enough for each classification. MSE and RMSE help
in clear view of time series model performance. The loss function
greatly influences the performance or accuracy of the model. Table II
represents the accuracy of each model for different dataset and classes
respresent the number of crime categories of the given data. Higer the
accuracy percentage better the performance of the model.

\begin{table}
\centering
\caption{\label{tab:unnamed-chunk-17}Comparision of machine and deep learing models}
\centering
\begin{tabular}[t]{l|l|l|l}
\hline
Model & SFO(2003-18) & SFO(2018-22) & Boston(2022)\\
\hline
RandomForest & 83.70 \% & 89.27 \% & 78.69 \%\\
\hline
K Neighbor & 98.79 \% & 98.59 \% & 72.70 \%\\
\hline
ANN & 86.07 \% & 81.63 \% & 55.58 \%\\
\hline
TabNet & 89.25 \% & 86.29 \% & 63.53 \%\\
\hline
Classes & 37 & 50 & 120\\
\hline
\end{tabular}
\end{table}

\section{VIII. Application and
Dashboard}\label{viii.-application-and-dashboard}

\subsection{A. Web Application}\label{a.-web-application}

To create the web application (henceforth referred as webapp) start with
YAML code as the first line of the jupyter notebook by providing the
required filters as part of the code. Define the dashboard name as part
of the WebAPP page. The webapp needs the mercury libraries. Hence,
install the libraries for python and use the command such as jupyter
trust, mercury add, and mercury watch on the created file. This will
initiate the webapp in the link locally ``http://127.0.0.1:8000'' .

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{img/fig14a} 

}

\caption{Webapp to identify the location and incidents}\label{fig:unnamed-chunk-18}
\end{figure}

\subsection{B. Interactive Dashboard}\label{b.-interactive-dashboard}

The interactive dashboard needs different python libraries for map and
interactive display. The folium library to display the map and
ipywidgets library for interactive display are required. The next step
is to identify the important features for the dashboard and followes the
initialization of the widgets for the features that are part of filter
conditions. The description and layout specify the display of the filter
in specific format. The function should be defined to get the data and
transform the data if necessary to required aggregation. Use folium
method to display map and any other chart if necessary. Use widget
interactive method to invoke the function and required widget that are
part of filters to display the interactive dashboard.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{img/fig14b} 

}

\caption{Interactive map to facilitate different requirements}\label{fig:unnamed-chunk-19}
\end{figure}

\section{IX. Limitation}\label{ix.-limitation}

This project is to predict the incident categories. The number of
categories may vary based on the data and location. It is not suitable
for identification of person or thing responsible for crime; Crimes were
categorized based on evidence produced and justified report. It is
difficult to get the census data based on city and geographical location
to map crimes categories with population based on crime hotspot and its
location.

\section{X. Conclusion and Future
Work}\label{x.-conclusion-and-future-work}

We always tend to move towards ML algorithms for classification problems
as it is white box, but there are other models like deep learning, time
series and TabNet for better accuracy and easy implmentation. Even
Though ML algorithms overcome the Deep learning and TabNet models, more
data and fine tuning of any models perform better for the given data.
This paper presents the performance and comparison of Machine learning
and deep learning models. It also includes the different methods like
Artificial Neural Network, TabNet and includes effective interactive
dashboard creation and webapp applications. The method is applied to
different datasets to explain the flexibility of the approach used. The
random forest comparison was done using both gini and entropy criteria,
wighted K-nearest neighbor using 100 estimators. A deep tabular data
learning called TabNet that uses sequential attention mechanisms and a
more effective fine-tuning approach is used. Each model is compared
across the confusion matrix and classification report. This project
deals with all the methods using python to make the users more friendly
and reduce infrastructure cost. It is easy to use the same method to any
crime dataset with little inital feature modification of the given data
to fit to the required format and attributes. Webapp and interactive map
gives friendly and better visualization of the data. The crimes are
concentrated towards the particular place, and it might be tagged to
population or poverty. Direction of the feature work is to get the
census data based on city and geographical location to link the crime to
specific location and its cause by considering population, social status
and education.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{0}
\bibitem[\citeproctext]{ref-tayebi2015learning}
\CSLLeftMargin{{[}1{]} }%
\CSLRightInline{M. A. Tayebi, U. Gla, P. L. Brantingham, \emph{et al.},
{``Learning where to inspect: Location learning for crime prediction,''}
in \emph{2015 IEEE international conference on intelligence and security
informatics (ISI)}, IEEE, 2015, pp. 25--30.}

\bibitem[\citeproctext]{ref-sherman1989hot}
\CSLLeftMargin{{[}2{]} }%
\CSLRightInline{L. W. Sherman, P. R. Gartin, and M. E. Buerger, {``Hot
spots of predatory crime: Routine activities and the criminology of
place,''} \emph{Criminology}, vol. 27, no. 1, pp. 27--56, 1989.}

\bibitem[\citeproctext]{ref-tayebi2012understanding}
\CSLLeftMargin{{[}3{]} }%
\CSLRightInline{M. A. Tayebi, R. Frank, and U. Glässer, {``Understanding
the link between social and spatial distance in the crime world,''} in
\emph{Proceedings of the 20th international conference on advances in
geographic information systems}, 2012, pp. 550--553.}

\bibitem[\citeproctext]{ref-brantingham2010nodes}
\CSLLeftMargin{{[}4{]} }%
\CSLRightInline{P. Brantingham and P. Brantingham, {``Nodes, paths, and
edges: Considerations on the complexity of crime and the physical
environment (1993),''} in \emph{Classics in environmental criminology},
Routledge, 2010, pp. 289--326.}

\bibitem[\citeproctext]{ref-rossmo1999geographic}
\CSLLeftMargin{{[}5{]} }%
\CSLRightInline{D. K. Rossmo, \emph{Geographic profiling}. CRC press,
1999.}

\bibitem[\citeproctext]{ref-weisburd2012criminology}
\CSLLeftMargin{{[}6{]} }%
\CSLRightInline{D. Weisburd, E. R. Groff, and S.-M. Yang, \emph{The
criminology of place: Street segments and our understanding of the crime
problem}. Oxford University Press, 2012.}

\bibitem[\citeproctext]{ref-suresh2021f}
\CSLLeftMargin{{[}7{]} }%
\CSLRightInline{H. Suresh and J. Guttag, {``A framework for
understanding sources of harm throughout the machine learning life
cycle,''} in \emph{Proceedings of the 1st ACM conference on equity and
access in algorithms, mechanisms, and optimization}, 2021, pp. 1--9.}

\bibitem[\citeproctext]{ref-darshan2022crime}
\CSLLeftMargin{{[}8{]} }%
\CSLRightInline{M. Darshan and S. Shankaraiah, {``Crime analysis and
prediction using machine learning algorithms,''} in \emph{2022 IEEE 2nd
mysore sub section international conference (MysuruCon)}, IEEE, 2022,
pp. 1--7.}

\bibitem[\citeproctext]{ref-gahalot2020crime}
\CSLLeftMargin{{[}9{]} }%
\CSLRightInline{A. Gahalot, S. Dhiman, L. Chouhan, \emph{et al.},
{``Crime prediction and analysis,''} in \emph{2nd international
conference on data, engineering and applications (IDEA)}, IEEE, 2020,
pp. 1--6.}

\bibitem[\citeproctext]{ref-pandya2022analysis}
\CSLLeftMargin{{[}10{]} }%
\CSLRightInline{D. D. Pandya, G. Amarawat, A. Jadeja, S. Degadwala, and
D. Vyas, {``Analysis and prediction of location based criminal behaviors
through machine learning,''} in \emph{2022 international conference on
edge computing and applications (ICECAA)}, IEEE, 2022, pp. 1324--1332.}

\bibitem[\citeproctext]{ref-yadav2017crime}
\CSLLeftMargin{{[}11{]} }%
\CSLRightInline{S. Yadav, M. Timbadia, A. Yadav, R. Vishwakarma, and N.
Yadav, {``Crime pattern detection, analysis \& prediction,''} in
\emph{2017 international conference of electronics, communication and
aerospace technology (ICECA)}, IEEE, 2017, pp. 225--230.}

\bibitem[\citeproctext]{ref-menaka2022analysis}
\CSLLeftMargin{{[}12{]} }%
\CSLRightInline{M. Menaka and B. Booba, {``Analysis to improve
classifier accuracy in crime data prediction,''} in \emph{2022 6th
international conference on computing methodologies and communication
(ICCMC)}, IEEE, 2022, pp. 721--725.}

\bibitem[\citeproctext]{ref-al2022intelligent}
\CSLLeftMargin{{[}13{]} }%
\CSLRightInline{A. H. Al-Ghushami, D. Syed, J. Sessa, and A. Zainab,
{``Intelligent automation of crime prediction using data mining,''} in
\emph{2022 IEEE 31st international symposium on industrial electronics
(ISIE)}, IEEE, 2022, pp. 245--252.}

\bibitem[\citeproctext]{ref-arik2021tabnet}
\CSLLeftMargin{{[}14{]} }%
\CSLRightInline{S. Ö. Arik and T. Pfister, {``Tabnet: Attentive
interpretable tabular learning,''} in \emph{Proceedings of the AAAI
conference on artificial intelligence}, 2021, pp. 6679--6687.}

\end{CSLReferences}

\end{document}

